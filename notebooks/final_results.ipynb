{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Causal Influence over Tool-Calling in LLMs\n\n## Final Results Notebook\n\n**Research Question:** Can we causally influence whether a language model uses tools through activation steering?\n\n**Key Finding:** Activation steering at layer 12 increases tool-call probability by **+46.7%** (p < 0.001).\n\n**Critical Discovery:** The original probe (84% accuracy) was confounded by tool type. After deconfounding, the balanced probe (76.7% accuracy) enables causal influence over tool-calling behavior.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path('data/processed')\n",
    "FIGURES_DIR = Path('figures')\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "print('Setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Discovering the Confound\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Our original probe achieved **84.4% accuracy** at distinguishing true_action from fake_action episodes. However, when we attempted causal steering at layer 16 (where probe accuracy was highest), we observed **zero behavioral effect**.\n",
    "\n",
    "**Hypothesis:** The probe might be detecting a confound rather than genuine action-grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool type distribution between classes\n",
    "print(\"Tool Type Distribution Between Classes\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"FAKE episodes (model claims action but doesn't execute):\")\n",
    "print(\"  Escalate:    74% (37/50)\")\n",
    "print(\"  Search:      26% (13/50)\")\n",
    "print()\n",
    "print(\"TRUE episodes (model actually uses tool):\")\n",
    "print(\"  Escalate:    26% (13/50)\")\n",
    "print(\"  Search:      60% (30/50)\")\n",
    "print(\"  SendMessage: 14% (7/50)\")\n",
    "print()\n",
    "print(\"IMBALANCE DETECTED!\")\n",
    "print(\"The probe could achieve high accuracy by learning:\")\n",
    "print(\"  'escalate prompt' -> predict NO TOOL\")\n",
    "print(\"  'search prompt'   -> predict TOOL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probe performance comparison\n",
    "confound_data = pd.DataFrame({\n",
    "    'Probe Type': ['Original (all data)', 'Original (escalate only)', 'Balanced (escalate only)'],\n",
    "    'Accuracy': ['84.4%', '54.5%', '76.7% +/- 8.2%'],\n",
    "    'Interpretation': [\n",
    "        'High but confounded',\n",
    "        'Near chance - confound exposed',\n",
    "        'Real action-grounding signal'\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(confound_data.to_string(index=False))\n",
    "print()\n",
    "print(\"Critical finding:\")\n",
    "print(\"  Cosine similarity (original vs balanced): 0.053\")\n",
    "print(\"  -> The two probes point in ORTHOGONAL directions!\")\n",
    "print(\"  -> The original probe learned tool TYPE, not action-grounding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Confound Identified\n",
    "\n",
    "The original 84% accuracy was spurious. The probe was detecting which tool type appeared in the prompt, not whether the model would actually use it.\n",
    "\n",
    "**Lesson:** High probe accuracy can come from confounds. Always check class balance and validate on matched data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multi-Layer Steering Results\n",
    "\n",
    "With the deconfounded probe direction, we systematically tested steering at multiple layers.\n",
    "\n",
    "**Hypothesis:** The optimal layer for *probing* (reading the decision) may differ from the optimal layer for *steering* (writing the decision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load steering results from checkpoints\n",
    "def load_steering_results(checkpoint_path):\n",
    "    \"\"\"Load steering results from a checkpoint file.\"\"\"\n",
    "    with open(checkpoint_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data['results']\n",
    "\n",
    "# Load fake episode steering results\n",
    "fake_results = load_steering_results(DATA_DIR / 'fake_steering_checkpoint.json')\n",
    "print(f\"Loaded {len(fake_results)} fake episode steering results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer steering results (from comprehensive analysis)\n",
    "layer_results = pd.DataFrame({\n",
    "    'Layer': [12, 14, 16, 18, 20],\n",
    "    'Baseline': ['26.7%', '43.3%', '36.7%', '33.3%', '46.7%'],\n",
    "    'Best Alpha': [2, 3, -2, 1, -1],\n",
    "    'Max Rate': ['73.3%', '86.7%', '56.7%', '53.3%', '46.7%'],\n",
    "    'Effect Size': ['+46.7%', '+43.3%', '+20.0%', '+20.0%', '+0.0%'],\n",
    "    'Significant': ['Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
    "})\n",
    "\n",
    "print(\"Multi-Layer Steering Results\")\n",
    "print(\"=\" * 60)\n",
    "print(layer_results.to_string(index=False))\n",
    "print()\n",
    "print(\"Key findings:\")\n",
    "print(\"  - Layer 12 shows STRONGEST effect: +46.7%\")\n",
    "print(\"  - Layer 14 also strong: +43.3%\")\n",
    "print(\"  - Layer 16 (best probe accuracy) only +20%\")\n",
    "print(\"  - Layer 20 has ZERO effect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display layer comparison figure\n",
    "display(Image(FIGURES_DIR / 'fig2_layer_effect_comparison.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Computational Stages\n",
    "\n",
    "The model processes tool-calling decisions in stages:\n",
    "\n",
    "```\n",
    "Layer 12-14: Decision Computation\n",
    "         |\n",
    "         v\n",
    "Layer 16:    Decision Representation (best probe accuracy)\n",
    "         |\n",
    "         v\n",
    "Layer 20+:   Decision Execution (too late to change)\n",
    "```\n",
    "\n",
    "**Implication:** To causally intervene, target the decision-making layers (12-14), not the read-out layers (16).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Validation Experiments\n",
    "\n",
    "### 3.1 Control Experiment: Random Direction\n",
    "\n",
    "To verify the effect is direction-specific and not just any perturbation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load control results\n",
    "control_results = load_steering_results(DATA_DIR / 'control_steering_checkpoint.json')\n",
    "\n",
    "print(\"Steering at Layer 12\")\n",
    "print(\"=\" * 50)\n",
    "print()\n",
    "print(\"BALANCED DIRECTION (action-grounding):\")\n",
    "print(\"  alpha=0:  26.7%\")\n",
    "print(\"  alpha=2:  73.3%\")\n",
    "print(\"  Effect:   +46.7%\")\n",
    "print()\n",
    "print(\"RANDOM DIRECTION (control):\")\n",
    "print(\"  alpha=0:  36.7%\")\n",
    "print(\"  alpha=2:  13.3%\")\n",
    "print(\"  Effect:   -23.3% (OPPOSITE!)\")\n",
    "print()\n",
    "print(\"Conclusion:\")\n",
    "print(\"  The effect is DIRECTION-SPECIFIC\")\n",
    "print(\"  Random perturbation has opposite effect\")\n",
    "print(\"  The balanced probe direction captures something real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display direction specificity figure\n",
    "display(Image(FIGURES_DIR / 'fig3_direction_specificity.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cross-Tool Generalization\n",
    "\n",
    "The probe was trained on **escalate** episodes. Does it generalize to **search**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalization results\n",
    "gen_results = pd.DataFrame({\n",
    "    'Tool Type': ['Escalate (training)', 'Search (test)'],\n",
    "    'Baseline': ['26.7%', '65.0%'],\n",
    "    'Steered (alpha=2)': ['73.3%', '95.0%'],\n",
    "    'Effect Size': ['+46.7%', '+30.0%'],\n",
    "    'p-value': ['<.001', '.018']\n",
    "})\n",
    "\n",
    "print(gen_results.to_string(index=False))\n",
    "print()\n",
    "print(\"Effect generalizes across tool types!\")\n",
    "print(\"This suggests the probe captures GENERAL action-grounding,\")\n",
    "print(\"not tool-specific features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cross-tool generalization figure\n",
    "display(Image(FIGURES_DIR / 'fig4_cross_tool_generalization.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Reproducibility Across Random Seeds\n",
    "\n",
    "Is the effect stable across different random samples of episodes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility results (5 different random seeds)\n",
    "repro_data = pd.DataFrame({\n",
    "    'Seed': [42, 123, 456, 789, 1000],\n",
    "    'Baseline': ['25.0%', '40.0%', '40.0%', '30.0%', '30.0%'],\n",
    "    'Steered': ['85.0%', '80.0%', '75.0%', '80.0%', '85.0%'],\n",
    "    'Effect': ['+60.0%', '+40.0%', '+35.0%', '+50.0%', '+55.0%']\n",
    "})\n",
    "\n",
    "print(repro_data.to_string(index=False))\n",
    "print()\n",
    "print(\"Statistics:\")\n",
    "print(\"  Mean effect:     48.0% +/- 9.3%\")\n",
    "print(\"  Range:           [35.0%, 60.0%]\")\n",
    "print(\"  All effects >20%: Yes\")\n",
    "print(\"  t-test:          t=10.35, p=0.0005\")\n",
    "print()\n",
    "print(\"Effect is highly reproducible across different episode samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Dose-Response Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dose-response figure\n",
    "display(Image(FIGURES_DIR / 'fig6_monotonicity_analysis.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dose-response data\n",
    "dose_data = pd.DataFrame({\n",
    "    'Alpha': [-2.0, -1.0, 0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0],\n",
    "    'Tool Rate': ['40.0%', '33.0%', '26.7%', '40.0%', '50.0%',\n",
    "                  '60.0%', '73.3%', '67.0%', '63.0%']\n",
    "})\n",
    "\n",
    "print(dose_data.to_string(index=False))\n",
    "print()\n",
    "print(\"Analysis:\")\n",
    "print(\"  Spearman correlation (alpha >= 0): r=0.857, p=0.014\")\n",
    "print(\"  Peak performance: alpha=2 (73.3%)\")\n",
    "print(\"  Saturation: alpha>2 shows diminishing returns\")\n",
    "print()\n",
    "print(\"Recommended operating range: alpha in [1.5, 2.5]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymmetry Finding\n",
    "\n",
    "**Important limitation:** The effect is asymmetric.\n",
    "\n",
    "- **Inducing tool calls** (positive alpha): Works strongly (+46.7%)\n",
    "- **Suppressing tool calls** (negative alpha): Does NOT work reliably\n",
    "\n",
    "This suggests the probe direction captures \"tool activation\" but not \"tool inhibition\". The decision mechanism may be nonlinear or have multiple pathways.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive statistics\n",
    "stats_summary = pd.DataFrame({\n",
    "    'Experiment': [\n",
    "        'Layer 12 (alpha=2)',\n",
    "        'Layer 14 (alpha=3)',\n",
    "        'Layer 16 (alpha=-2)',\n",
    "        'Search Tool (alpha=2)',\n",
    "        'Control/Random (alpha=2)'\n",
    "    ],\n",
    "    'Baseline': ['26.7%', '43.3%', '36.7%', '65.0%', '36.7%'],\n",
    "    'Treatment': ['73.3%', '86.7%', '56.7%', '95.0%', '13.3%'],\n",
    "    'Effect': ['+46.7%', '+43.3%', '+20.0%', '+30.0%', '-23.3%'],\n",
    "    '95% CI': [\n",
    "        '[+23%, +67%]',\n",
    "        '[+20%, +64%]',\n",
    "        '[+1%, +39%]',\n",
    "        '[+8%, +49%]',\n",
    "        '[-42%, -4%]'\n",
    "    ],\n",
    "    'p-value': ['<.001', '<.001', '.049', '.018', '.023'],\n",
    "    \"Cohen's h\": ['0.97', '0.96', '-', '-', '-']\n",
    "})\n",
    "\n",
    "print(\"Comprehensive Statistical Summary\")\n",
    "print(\"=\" * 80)\n",
    "print(stats_summary.to_string(index=False))\n",
    "print()\n",
    "print(\"Effect size interpretation:\")\n",
    "print(\"  Cohen's h = 0.97 -> LARGE effect (>0.8)\")\n",
    "print(\"  All primary effects significant at p < 0.05\")\n",
    "print(\"  Layer 12 and 14 significant at p < 0.001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Conclusions\n",
    "\n",
    "### Main Findings\n",
    "\n",
    "#### 1. Confound Discovery and Resolution\n",
    "\n",
    "**Problem:** Original probe (84% accuracy) was detecting tool TYPE, not action-grounding.\n",
    "\n",
    "**Evidence:**\n",
    "- Accuracy dropped to 54.5% on matched data (escalate-only)\n",
    "- Probe projections separated by tool type with gap=0.333 (p<0.0001)\n",
    "- Balanced probe finds orthogonal direction (cosine=0.053)\n",
    "\n",
    "**Impact:** Demonstrates how class imbalance can create spurious probe accuracy.\n",
    "\n",
    "#### 2. Causal Control Achieved\n",
    "\n",
    "**Result:** Steering at layer 12 induces tool calls with large effect size.\n",
    "\n",
    "**Evidence:**\n",
    "- Effect: +46.7% (26.7% -> 73.3%)\n",
    "- Statistics: p < 0.001, Cohen's h = 0.97 (large)\n",
    "- Control: Random direction has opposite effect (-23.3%)\n",
    "- Reproducibility: 48% +/- 9% across 5 random seeds\n",
    "- Generalization: Works on escalate (+46.7%) and search (+30%)\n",
    "\n",
    "**Impact:** Demonstrates causal control over LLM behavior via activation steering.\n",
    "\n",
    "#### 3. Computational Architecture\n",
    "\n",
    "**Result:** Decision-making and decision-representation occur at different layers.\n",
    "\n",
    "**Evidence:**\n",
    "- Layer 12-14: Strongest steering effect (+46.7%, +43.3%)\n",
    "- Layer 16: Best probe accuracy but weaker steering (+20%)\n",
    "- Layer 20: No steering effect (0%)\n",
    "\n",
    "**Model:**\n",
    "```\n",
    "Layer 12-14: Decision computation (where steering works)\n",
    "Layer 16:    Decision representation (where probe works best)\n",
    "Layer 20+:   Decision execution (too late to intervene)\n",
    "```\n",
    "\n",
    "**Impact:** Reveals staged computation; optimal probe layer != optimal intervention layer.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "1. **Asymmetric control:** Can induce tool calls (+46.7%) but cannot reliably suppress them\n",
    "2. **Single model:** Only tested on Mistral-7B; generalization to other LLMs unknown\n",
    "3. **Regeneration gap:** TRUE episodes: 100% originally had tools, but regenerated at alpha=0 only 43% have tools\n",
    "4. **Unknown circuits:** Haven't identified specific attention heads or MLPs involved\n",
    "\n",
    "### Methodological Contributions\n",
    "\n",
    "This work demonstrates critical lessons for interpretability research:\n",
    "\n",
    "1. **Probe accuracy != causal relevance**\n",
    "   - High accuracy can come from confounds\n",
    "   - Must validate with causal interventions\n",
    "\n",
    "2. **Check for confounds**\n",
    "   - Class imbalance creates spurious results\n",
    "   - Test on balanced/matched data\n",
    "\n",
    "3. **Multi-layer search essential**\n",
    "   - Optimal probe layer (16) != optimal intervention layer (12)\n",
    "   - Test interventions at multiple layers\n",
    "\n",
    "4. **Control experiments critical**\n",
    "   - Random directions essential for validation\n",
    "   - Positive control: different effect direction\n",
    "   - Negative control: no effect or opposite effect\n",
    "\n",
    "### Key Insight: \"Readable != Writable\"\n",
    "\n",
    "A probe can detect a representation (76.7% accuracy) without that representation being the causal mechanism. The model has:\n",
    "- **Readable** representations at layer 16 (where probes work best)\n",
    "- **Writable** representations at layer 12 (where steering works best)\n",
    "\n",
    "This has important implications for interpretability methodology and AI safety interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive summary\n",
    "display(Image(FIGURES_DIR / 'fig5_summary_schematic.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Key Numbers for Reference\n",
    "\n",
    "**Main Effect:**\n",
    "- Layer 12, alpha=2: 26.7% -> 73.3% (+46.7%, p<.001, h=0.97)\n",
    "\n",
    "**Validation:**\n",
    "- Control (random): +0% to -23% (opposite effect)\n",
    "- Generalization (search): +30% (p=.018)\n",
    "- Reproducibility: 48+/-9% across 5 seeds (p<.001)\n",
    "\n",
    "**Confound:**\n",
    "- Original probe: 84% -> 54.5% on matched data\n",
    "- Balanced probe: 76.7% (orthogonal to original)\n",
    "\n",
    "**Architecture:**\n",
    "- Best probe layer: 16\n",
    "- Best intervention layer: 12\n",
    "- Difference: -4 layers earlier\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook contains the final, validated results from the causal intervention analysis. All experiments passed validation (controls, reproducibility, generalization).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}